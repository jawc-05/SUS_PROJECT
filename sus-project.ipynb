{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13686714,"sourceType":"datasetVersion","datasetId":8644471}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# T3: Analize de Dados do SiaSUS\n\nForma: Trabalho em grupo com apresenta√ß√£o do ambiente e do c√≥digo para o professor.\n\nObjetivo:\nNesta primeira parte, que deve estar pronta para a aula do dia 03/11/2025, os grupos devem obter, preparar e carregar em um banco de dados relacional os dados do SIASUS (Sistema de Informa√ß√µes Ambulatoriais do SUS), disponibilizados publicamente pelo DataSUS.\n\nInstru√ß√µes:\n1. 1) Obten√ß√£o da base de dados\n - Acesse o reposit√≥rio do DataSUS e fa√ßa o download dos arquivos do SIASUS no formato .dbc.\n - Selecione os arquivos referentes a procedimentos ambulatoriais (ex.: PARS e outros complementares necess√°rios para a descri√ß√£o da tabela PARS).\n2. 2) Convers√£o de formato\n - Converta os arquivos .dbc para .dbf utilizando as ferramentas recomendadas (ex.: TABWIN).\n - Certifique-se de validar a integridade dos arquivos ap√≥s a convers√£o.\n3) Visualiza√ß√£o dos dados\n - Utilize o TABWIN, software oficial do DataSUS, para visualizar os arquivos .dbf.\n - A partir do TABWIN, gere:\n  - Scripts SQL de cria√ß√£o de tabelas.\n4) Carga dos dados em SGBD:\n - Insira os dados no banco de dados relacional de sua escolha (ex. MySQL, PostgreSQL, IBM DB2, etc).\n - Para arquivos menores, utilize diretamente os scripts de inser√ß√£o gerados pelo TABWIN.\n - Para arquivos muito grandes (como o PARS, que cont√©m milh√µes de registros), gere um arquivo CSV a partir do .dbf e utilize um comando de LOAD (carga em lote) no SGBD escolhido.\n - Se optar pelo MySQL (que foi o utilizado em aula):\n  - Pesquise e utilize a instru√ß√£o LOAD DATA na linha de comando do servidor (para evitar problemas de permiss√µes com o cliente Workbench) conforme a documenta√ß√£o oficial: https://dev.mysql.com/doc/refman/8.4/en/load-data.html\nExemplo de comando LOAD DATA no terminal do servidor: LOAD DATA INFILE 'C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/PARS2508.csv' INTO TABLE pars CHARACTER SET latin1 FIELDS TERMINATED BY ',' ENCLOSED BY '\"' LINES  TERMINATED BY '\\r\\n' IGNORE 1 ROWS; \n5) A continuidade do trabalho, na aula do dia 03/11/2025, depende do ambiente do banco de dados funcionando.","metadata":{}},{"cell_type":"markdown","source":"## Principais libs que usaremos: ","metadata":{}},{"cell_type":"code","source":"# Esse projeto foi feito com o objetivo educativo para a mat√©ria de Program√ß√£o para Ci√™ncia dos dados\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# /kaggle/input/sus-data-csv/CADGERRS.csv","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Declarando arquivos:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Define o caminho base para facilitar (opcional, mas limpo)\nbase_path = '/kaggle/input/'\n\n# --- 1. TAREFAS FATO (Os eventos, a produ√ß√£o) ---\n# Estas s√£o as tabelas principais. Elas registram os eventos (atendimentos).\n# Os nomes (PARS2501, PARS2505, PARS2508) sugerem que s√£o dados mensais\n# (ex: Janeiro, Maio, Agosto de 2025). Vamos carreg√°-los e junt√°-los.\n\nprint(\"Carregando tabelas de produ√ß√£o (PARS)...\")\n\n# O que √©: Tabela FATO - Produ√ß√£o Ambulatorial (Parte 1, ex: M√™s 1)\n# O que vamos contar: Registros de procedimentos, valores, local, paciente, etc.\ndf_prod_01 = pd.read_csv(base_path + 'PARS2501.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela FATO - Produ√ß√£o Ambulatorial (Parte 2, ex: M√™s 5)\n# O que vamos contar: Mais registros de procedimentos...\ndf_prod_05 = pd.read_csv(base_path + 'PARS2505.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela FATO - Produ√ß√£o Ambulatorial (Parte 3, ex: M√™s 8)\n# O que vamos contar: Mais registros de procedimentos...\ndf_prod_08 = pd.read_csv(base_path + 'PARS2508.csv', encoding='latin1', low_memory=False)\n\n# --- 2. TAREFAS DIMENS√ÉO (Os dicion√°rios, \"de-para\") ---\n# Estas s√£o as tabelas auxiliares que d√£o nome aos c√≥digos das tabelas FATO.\n\nprint(\"Carregando tabelas de dimens√£o (dicion√°rios)...\")\n\n# O que √©: Tabela de Procedimentos (SIGTAP)\n# O que vamos usar: Dar nome aos c√≥digos de procedimento (ex: '0301010072' -> 'CONSULTA MEDICA')\ndf_procedimentos = pd.read_csv(base_path + 'TB_SIGTAW.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela de Munic√≠pios (IBGE)\n# O que vamos usar: Dar nome aos c√≥digos de munic√≠pio (ex: '431020' -> 'Iju√≠').\n# ESSENCIAL para a an√°lise de fluxo de pacientes (item 4 do seu trabalho).\ndf_municipios = pd.read_csv(base_path + 'tb_municip.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela de Doen√ßas (Classifica√ß√£o Internacional de Doen√ßas - CID)\n# O que vamos usar: Dar nome aos c√≥digos de diagn√≥stico (ex: 'I10' -> 'Hipertens√£o Essencial').\ndf_cid = pd.read_csv(base_path + 'S_CID.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela de Ocupa√ß√µes (Classifica√ß√£o Brasileira de Ocupa√ß√µes - CBO)\n# O que vamos usar: Dar nome aos c√≥digos de ocupa√ß√£o do profissional\n# (ex: '225125' -> 'M√©dico Cl√≠nico').\ndf_cbo = pd.read_csv(base_path + 'CBO.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Cadastro de Estabelecimentos (CNES)\n# O que vamos usar: Dar nome e endere√ßo aos c√≥digos de hospitais, cl√≠nicas e UBS\n# (ex: '2254611' -> 'HOSPITAL DE CARIDADE DE IJUI').\ndf_estabelecimentos = pd.read_csv(base_path + 'CADGERRS.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela de Rela√ß√£o (RL) Munic√≠pio -> Microrregi√£o\n# O que vamos usar: Ligar um c√≥digo de munic√≠pio a um c√≥digo de microrregi√£o.\ndf_rl_mun_micro = pd.read_csv(base_path + 'rl_municip_micibge.csv', encoding='latin1', low_memory=False)\n\n# O que √©: Tabela de Microrregi√µes (IBGE)\n# O que vamos usar: Dar nome ao c√≥digo da microrregi√£o (ex: '11001' -> 'Porto Velho').\ndf_microrregioes = pd.read_csv(base_path + 'tb_micibge.csv', encoding='latin1', low_memory=False)\n\nprint(\"\\nTodos os arquivos foram carregados com sucesso!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Junta as 3 tabelas de produ√ß√£o (uma em cima da outra)\ndf_producao_total = pd.concat([df_prod_01, df_prod_05, df_prod_08], ignore_index=True)\n\n# Libera a mem√≥ria, j√° que n√£o precisamos mais das partes separadas\ndel df_prod_01\ndel df_prod_05\ndel df_prod_08\n\nprint(f\"Tabelas de produ√ß√£o combinadas!\")\nprint(f\"Total de registros para analisar: {len(df_producao_total)}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_producao_total.head(n=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df_producao_total.columns.tolist())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela principal (produ√ß√£o) √© 'PA_MUNPCN'\nchave_principal = 'PA_MUNPCN'\n\n# A chave da nossa tabela auxiliar (munic√≠pios) √© 'CO_MUNICIP'\nchave_auxiliar = 'CO_MUNICIP'\n\n# Converte ambas as colunas-chave para string (texto) para garantir o merge\ndf_producao_total[chave_principal] = df_producao_total[chave_principal].astype(str)\ndf_municipios[chave_auxiliar] = df_municipios[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos criar nosso dataframe de an√°lise final, come√ßando com este merge\n# Puxamos apenas as colunas de nome e UF da tabela de munic√≠pios\ndf_analise = pd.merge(\n    left=df_producao_total,\n    right=df_municipios[['CO_MUNICIP', 'DS_NOME', 'CO_UF']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '431020')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '431020')\n    how='left'                 # 'left' garante que n√£o vamos perder nenhuma linha da principal\n)\n\nprint(\"Merge com Munic√≠pios conclu√≠do!\")\n\n# Vamos verificar o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\n\n# Vamos renomear as colunas para ficar mais claro\ndf_analise.rename(columns={'DS_NOME': 'MUNICIPIO_PACIENTE', 'CO_UF': 'UF_PACIENTE'}, inplace=True)\n\n# Mostra as colunas originais e as novas que foram \"puxadas\"\nprint(df_analise[['PA_MUNPCN', 'MUNICIPIO_PACIENTE', 'UF_PACIENTE']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_PROC_ID'\nchave_principal = 'PA_PROC_ID'\n\n# A chave da nossa tabela auxiliar (procedimentos) √© 'IP_COD'\nchave_auxiliar = 'IP_COD'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_procedimentos[chave_auxiliar] = df_procedimentos[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Agora fazemos o merge no 'df_analise' (que j√° tem os nomes dos munic√≠pios)\n# Vamos puxar apenas a coluna 'IP_DSCR' (Descri√ß√£o do Procedimento)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_procedimentos[['IP_COD', 'IP_DSCR']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '0301010072')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '0301010072')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Procedimentos conclu√≠do!\")\n\n# Vamos renomear a nova coluna para ficar claro\ndf_analise.rename(columns={'IP_DSCR': 'NOME_PROCEDIMENTO'}, inplace=True)\n\n# Verifica o resultado, mostrando a coluna do c√≥digo e a nova coluna com o nome\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_PROC_ID', 'NOME_PROCEDIMENTO']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CODUNI'\nchave_principal = 'PA_CODUNI'\n\n# A chave da nossa tabela auxiliar (estabelecimentos) √© 'CNES'\nchave_auxiliar = 'CNES'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_estabelecimentos[chave_auxiliar] = df_estabelecimentos[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar o 'NOME FANTASIA' e a 'RAZAO SOCIAL' do estabelecimento\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_estabelecimentos[['CNES', 'FANTASIA', 'RAZ_SOCI']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '2254611')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '2254611')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Estabelecimentos conclu√≠do!\")\n\n# Renomeia as colunas para ficar mais claro\ndf_analise.rename(columns={\n    'FANTASIA': 'NOME_ESTABELECIMENTO',\n    'RAZ_SOCI': 'RAZAO_SOCIAL_ESTAB'\n}, inplace=True)\n\n# Verifica o resultado, mostrando o c√≥digo e os novos nomes\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CODUNI', 'NOME_ESTABELECIMENTO']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CIDPRI'\nchave_principal = 'PA_CIDPRI'\n\n# A chave da nossa tabela auxiliar (CID) √© 'CD_COD'\nchave_auxiliar = 'CD_COD'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_cid[chave_auxiliar] = df_cid[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar a 'CD_DESCR' (Descri√ß√£o do CID)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_cid[['CD_COD', 'CD_DESCR']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: 'I10')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: 'I10')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Diagn√≥sticos (CID) conclu√≠do!\")\n\n# Renomeia a coluna para ficar mais claro\ndf_analise.rename(columns={'CD_DESCR': 'NOME_DIAGNOSTICO'}, inplace=True)\n\n# Verifica o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CIDPRI', 'NOME_DIAGNOSTICO']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CBOCOD'\nchave_principal = 'PA_CBOCOD'\n\n# A chave da nossa tabela auxiliar (CBO) √© 'CBO'\nchave_auxiliar = 'CBO'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_cbo[chave_auxiliar] = df_cbo[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar a 'DS_CBO' (Descri√ß√£o do CBO)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_cbo[['CBO', 'DS_CBO']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '225125')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '225125')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Ocupa√ß√µes (CBO) conclu√≠do!\")\n\n# Renomeia a coluna para ficar mais claro\ndf_analise.rename(columns={'DS_CBO': 'NOME_OCUPACAO'}, inplace=True)\n\n# Verifica o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CBOCOD', 'NOME_OCUPACAO']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# An√°lise em iju√≠","metadata":{}},{"cell_type":"markdown","source":"# Merge de tabelas apenas com os dados de \"Iju√≠\"\nNeste ponto reduzimos **13.2 milh√µes** de linhas para **160 mil registros** (os que realmente importam para Iju√≠) essa a√ß√£o √© crucial para o bom andamento dos testes a seguir, melhorando muito nossa efici√™ncia!\n\n- O uso de mem√≥ria caiu de **7.4+ GB** para apenas **86.7 MB**.\n- Agora temos uma tabela leve, r√°pida e com todas as informa√ß√µes que precisamos para a an√°lise","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nprint(\"--- Iniciando An√°lise Focada em Iju√≠ ---\")\n\n# --- PASSO 1: Encontrar o C√≥digo de Iju√≠ ---\n# (Precisamos que a chave df_municipios['CO_MUNICIP'] j√° seja string)\ntry:\n    ijui_info = df_municipios[df_municipios['DS_NOME'] == 'Ijui']\n    codigo_ijui_str = ijui_info['CO_MUNICIP'].values[0]\n    \n    # A coluna PA_UFMUN (Munic√≠pio do Estabelecimento) √© int64 (n√∫mero)\n    # Precisamos converter o c√≥digo de Iju√≠ para int para o filtro funcionar\n    codigo_ijui_int = int(codigo_ijui_str)\n    \n    print(f\"C√≥digo de Iju√≠ encontrado: {codigo_ijui_int} (como n√∫mero)\")\n\nexcept Exception as e:\n    print(f\"ERRO: N√£o foi poss√≠vel encontrar o c√≥digo de Iju√≠. Verifique se df_municipios est√° carregado.\")\n    print(f\"Detalhe do erro: {e}\")\n\n# --- PASSO 2: Filtrar a Tabela Gigante (13M de linhas) ---\nprint(f\"Filtrando {len(df_producao_total)} registros para focar apenas em Iju√≠...\")\n\n# Criamos um NOVO DataFrame S√ì com atendimentos feitos em estabelecimentos de Iju√≠\n# Usamos .copy() para garantir que √© um objeto novo e evitar erros de mem√≥ria\ndf_ijui_producao = df_producao_total[df_producao_total['PA_UFMUN'] == codigo_ijui_int].copy()\n\nprint(f\"Filtro Conclu√≠do! Tabela reduzida para {len(df_ijui_producao)} registros.\")\n\n# --- PASSO 3: Preparar Chaves da Nova Tabela de Iju√≠ ---\n# Agora, convertemos as chaves de merge *desta tabela pequena* para string\nprint(\"Preparando chaves da tabela de Iju√≠ para os merges...\")\ndf_ijui_producao['PA_MUNPCN'] = df_ijui_producao['PA_MUNPCN'].astype(str)\ndf_ijui_producao['PA_PROC_ID'] = df_ijui_producao['PA_PROC_ID'].astype(str)\ndf_ijui_producao['PA_CODUNI'] = df_ijui_producao['PA_CODUNI'].astype(str)\ndf_ijui_producao['PA_CIDPRI'] = df_ijui_producao['PA_CIDPRI'].astype(str)\ndf_ijui_producao['PA_CBOCOD'] = df_ijui_producao['PA_CBOCOD'].astype(str)\n\n# --- PASSO 4: Executar Merges na Tabela Pequena de Iju√≠ ---\nprint(\"Iniciando merges...\")\n\n# Merge 1: Munic√≠pio do Paciente (Onde o paciente mora)\ndf_analise = pd.merge(df_ijui_producao, df_municipios[['CO_MUNICIP', 'DS_NOME', 'CO_UF']], \n                      left_on='PA_MUNPCN', right_on='CO_MUNICIP', how='left')\ndf_analise.rename(columns={'DS_NOME': 'MUNICIPIO_PACIENTE', 'CO_UF': 'UF_PACIENTE'}, inplace=True)\nprint(\"Merge 1/5 (Munic√≠pio Paciente) OK\")\n\n# Merge 2: Nome do Procedimento\ndf_analise = pd.merge(df_analise, df_procedimentos[['IP_COD', 'IP_DSCR']], \n                      left_on='PA_PROC_ID', right_on='IP_COD', how='left')\ndf_analise.rename(columns={'IP_DSCR': 'NOME_PROCEDIMENTO'}, inplace=True)\nprint(\"Merge 2/5 (Nome Procedimento) OK\")\n\n# Merge 3: Nome do Estabelecimento (Hospital, UBS)\ndf_analise = pd.merge(df_analise, df_estabelecimentos[['CNES', 'FANTASIA']], \n                      left_on='PA_CODUNI', right_on='CNES', how='left')\ndf_analise.rename(columns={'FANTASIA': 'NOME_ESTABELECIMENTO'}, inplace=True)\nprint(\"Merge 3/5 (Nome Estabelecimento) OK\")\n\n# Merge 4: Nome do Diagn√≥stico (Doen√ßa)\ndf_analise = pd.merge(df_analise, df_cid[['CD_COD', 'CD_DESCR']], \n                      left_on='PA_CIDPRI', right_on='CD_COD', how='left')\ndf_analise.rename(columns={'CD_DESCR': 'NOME_DIAGNOSTICO'}, inplace=True)\nprint(\"Merge 4/5 (Nome Diagn√≥stico) OK\")\n\n# Merge 5: Nome da Ocupa√ß√£o (Profissional)\ndf_analise = pd.merge(df_analise, df_cbo[['CBO', 'DS_CBO']], \n                      left_on='PA_CBOCOD', right_on='CBO', how='left')\ndf_analise.rename(columns={'DS_CBO': 'NOME_OCUPACAO'}, inplace=True)\nprint(\"Merge 5/5 (Nome Ocupa√ß√£o) OK\")\n\nprint(\"\\n--- üíæ AN√ÅLISE DE IJU√ç PRONTA E CARREGADA ---\")\n\n# --- PASSO 5: Verificar Resultado ---\n# Vamos ver o resultado e o novo uso de mem√≥ria\ndf_analise.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}