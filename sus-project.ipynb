{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13686714,"sourceType":"datasetVersion","datasetId":8644471}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# T3: An√°lise de Dados do SIASUS\n\nEste trabalho apresenta uma an√°lise explorat√≥ria e estrat√©gica dos dados do Sistema de Informa√ß√µes Ambulatoriais do SUS (SIASUS), com foco na produ√ß√£o ambulatorial do munic√≠pio de Iju√≠/RS. Diante da complexidade e do grande volume de dados (13.2 milh√µes de registros), aplicou-se um processo de extra√ß√£o, transforma√ß√£o e carregamento (ETL), seguido de uma an√°lise detalhada sobre a base filtrada de 160.060 procedimentos locais.\n\nO objetivo √© converter dados t√©cnicos em um diagn√≥stico preciso, identificando os principais perfis de atendimento (Itens 1-3), os fluxos regionais de pacientes (Item 4), os vetores de custo financeiro (Item 5), as √°reas cr√≠ticas de alta complexidade (Item 6) e o posicionamento de Iju√≠ frente a outros polos regionais (Item 7), servindo como alicerce para a tomada de decis√£o da gest√£o municipal.","metadata":{}},{"cell_type":"markdown","source":"### Principais libs que usaremos: ","metadata":{}},{"cell_type":"code","source":"# Esse projeto foi feito com o objetivo educativo para a mat√©ria de Program√ß√£o para Ci√™ncia dos dados\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:01:58.264993Z","iopub.execute_input":"2025-11-13T01:01:58.265715Z","iopub.status.idle":"2025-11-13T01:01:58.273812Z","shell.execute_reply.started":"2025-11-13T01:01:58.265674Z","shell.execute_reply":"2025-11-13T01:01:58.272396Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Aqui iremos definir o valor de cada data frame e tamb√©m juntando os valores dos 3 arquivos de **PARS** (Apenas com os dados de Iju√≠):","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Define o caminho base\nbase_path = '/kaggle/input/'\n\n# --- 1. CARREGA AS TABELAS DIMENS√ÉO (DICION√ÅRIOS) ---\n# (Carregamos estas primeiro, pois s√£o leves e precisamos delas para o filtro)\n\nprint(\"Carregando tabelas de dimens√£o (dicion√°rios)...\")\n\ndf_procedimentos = pd.read_csv(base_path + 'TB_SIGTAW.csv', encoding='latin1', low_memory=False)\ndf_municipios = pd.read_csv(base_path + 'tb_municip.csv', encoding='latin1', low_memory=False)\ndf_cid = pd.read_csv(base_path + 'S_CID.csv', encoding='latin1', low_memory=False)\ndf_cbo = pd.read_csv(base_path + 'CBO.csv', encoding='latin1', low_memory=False)\ndf_estabelecimentos = pd.read_csv(base_path + 'CADGERRS.csv', encoding='latin1', low_memory=False)\ndf_rl_mun_micro = pd.read_csv(base_path + 'rl_municip_micibge.csv', encoding='latin1', low_memory=False)\ndf_microrregioes = pd.read_csv(base_path + 'tb_micibge.csv', encoding='latin1', low_memory=False)\n\nprint(\"Dicion√°rios carregados.\")\n\n# --- 2. PREPARA AS CHAVES DOS DICION√ÅRIOS ---\n# (Corrigimos os tipos de dados dos dicion√°rios, essencial para os merges futuros)\nprint(\"Preparando chaves dos dicion√°rios...\")\ndf_municipios['CO_MUNICIP'] = df_municipios['CO_MUNICIP'].astype(str)\ndf_procedimentos['IP_COD'] = df_procedimentos['IP_COD'].astype(str)\ndf_cid['CD_COD'] = df_cid['CD_COD'].astype(str)\ndf_cbo['CBO'] = df_cbo['CBO'].astype(str)\ndf_estabelecimentos['CNES'] = df_estabelecimentos['CNES'].astype(str)\n\n# --- 3. ENCONTRA O C√ìDIGO DE IJU√ç ---\ntry:\n    ijui_info = df_municipios[df_municipios['DS_NOME'] == 'Ijui'] # (Iju√≠ aqui n√£o tem acento)\n    codigo_ijui_str = ijui_info['CO_MUNICIP'].values[0]\n    codigo_ijui_int = int(codigo_ijui_str)\n    print(f\"C√≥digo de Iju√≠ ('Ijui') encontrado: {codigo_ijui_int}\")\nexcept Exception as e:\n    print(f\"ERRO: N√£o foi poss√≠vel encontrar o c√≥digo de Iju√≠. {e}\")\n\n# --- 4. LEITURA OTIMIZADA (CHUNKSIZE) DAS TABELAS FATO ---\n# Aqui lemos os 3 arquivos grandes em \"peda√ßos\", filtrando S√ì por Iju√≠\n\narquivos_producao = [\n    base_path + 'PARS2501.csv',\n    base_path + 'PARS2505.csv',\n    base_path + 'PARS2508.csv'\n]\nlista_chunks_ijui = []\nprint(\"Iniciando leitura otimizada (foco em Iju√≠)...\")\n\nfor arquivo in arquivos_producao:\n    print(f\"Processando arquivo: {arquivo}\")\n    with pd.read_csv(arquivo, encoding='latin1', low_memory=False, chunksize=500000) as reader:\n        for chunk in reader:\n            # Filtra o peda√ßo (chunk) para pegar APENAS as linhas de Iju√≠\n            chunk_filtrado_ijui = chunk[chunk['PA_UFMUN'] == codigo_ijui_int]\n            \n            if not chunk_filtrado_ijui.empty:\n                lista_chunks_ijui.append(chunk_filtrado_ijui)\n\nprint(\"Leitura em chunks conclu√≠da!\")\n\n# --- 5. CRIA O DF_PRODUCAO_TOTAL (S√ì DE IJU√ç) ---\ndf_producao_total = pd.concat(lista_chunks_ijui, ignore_index=True)\n\nprint(f\"\\n--- üíæ df_producao_total (s√≥ Iju√≠) criado com sucesso ---\")\nprint(f\"Total de registros de Iju√≠ encontrados: {len(df_producao_total)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:01:58.275886Z","iopub.execute_input":"2025-11-13T01:01:58.276224Z","iopub.status.idle":"2025-11-13T01:04:29.186540Z","shell.execute_reply.started":"2025-11-13T01:01:58.276185Z","shell.execute_reply":"2025-11-13T01:04:29.184851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Neste ponto reduzimos **13.2 milh√µes** de linhas para **160 mil registros** (os que realmente importam para Iju√≠) essa a√ß√£o √© crucial para o bom andamento dos testes a seguir, melhorando muito nossa efici√™ncia!\n\n- O uso de mem√≥ria caiu de **7.4+ GB** para apenas **86.7 MB**.\n- Agora temos uma tabela leve, r√°pida e com todas as informa√ß√µes que precisamos para a an√°lise","metadata":{}},{"cell_type":"code","source":"print(df_producao_total.columns.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.188857Z","iopub.execute_input":"2025-11-13T01:04:29.189338Z","iopub.status.idle":"2025-11-13T01:04:29.196465Z","shell.execute_reply.started":"2025-11-13T01:04:29.189294Z","shell.execute_reply":"2025-11-13T01:04:29.195138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Agora vamos garantir que as tabelas que vamos dar o merge tem o mesmo tipo de dado e a mesma formata√ß√£o","metadata":{}},{"cell_type":"code","source":"# A chave da nossa tabela principal (produ√ß√£o) √© 'PA_MUNPCN'\nchave_principal = 'PA_MUNPCN'\n\n# A chave da nossa tabela auxiliar (munic√≠pios) √© 'CO_MUNICIP'\nchave_auxiliar = 'CO_MUNICIP'\n\n# Converte ambas as colunas-chave para string (texto) para garantir o merge\ndf_producao_total[chave_principal] = df_producao_total[chave_principal].astype(str)\ndf_municipios[chave_auxiliar] = df_municipios[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.198058Z","iopub.execute_input":"2025-11-13T01:04:29.198373Z","iopub.status.idle":"2025-11-13T01:04:29.282947Z","shell.execute_reply.started":"2025-11-13T01:04:29.198349Z","shell.execute_reply":"2025-11-13T01:04:29.281429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos criar nosso dataframe de an√°lise final, come√ßando com este merge\n# Puxamos apenas as colunas de nome e UF da tabela de munic√≠pios\ndf_analise = pd.merge(\n    left=df_producao_total,\n    right=df_municipios[['CO_MUNICIP', 'DS_NOME', 'CO_UF']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '431020')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '431020')\n    how='left'                 # 'left' garante que n√£o vamos perder nenhuma linha da principal\n)\n\nprint(\"Merge com Munic√≠pios conclu√≠do!\")\n\n# Vamos verificar o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\n\n# Vamos renomear as colunas para ficar mais claro\ndf_analise.rename(columns={'DS_NOME': 'MUNICIPIO_PACIENTE', 'CO_UF': 'UF_PACIENTE'}, inplace=True)\n\n# Mostra as colunas originais e as novas que foram \"puxadas\"\nprint(df_analise[['PA_MUNPCN', 'MUNICIPIO_PACIENTE', 'UF_PACIENTE']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.286446Z","iopub.execute_input":"2025-11-13T01:04:29.287466Z","iopub.status.idle":"2025-11-13T01:04:29.538674Z","shell.execute_reply.started":"2025-11-13T01:04:29.287419Z","shell.execute_reply":"2025-11-13T01:04:29.537296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_PROC_ID'\nchave_principal = 'PA_PROC_ID'\n\n# A chave da nossa tabela auxiliar (procedimentos) √© 'IP_COD'\nchave_auxiliar = 'IP_COD'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_procedimentos[chave_auxiliar] = df_procedimentos[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.539979Z","iopub.execute_input":"2025-11-13T01:04:29.540343Z","iopub.status.idle":"2025-11-13T01:04:29.611151Z","shell.execute_reply.started":"2025-11-13T01:04:29.540316Z","shell.execute_reply":"2025-11-13T01:04:29.609196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Agora fazemos o merge no 'df_analise' (que j√° tem os nomes dos munic√≠pios)\n# Vamos puxar apenas a coluna 'IP_DSCR' (Descri√ß√£o do Procedimento)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_procedimentos[['IP_COD', 'IP_DSCR']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '0301010072')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '0301010072')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Procedimentos conclu√≠do!\")\n\n# Vamos renomear a nova coluna para ficar claro\ndf_analise.rename(columns={'IP_DSCR': 'NOME_PROCEDIMENTO'}, inplace=True)\n\n# Verifica o resultado, mostrando a coluna do c√≥digo e a nova coluna com o nome\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_PROC_ID', 'NOME_PROCEDIMENTO']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.612699Z","iopub.execute_input":"2025-11-13T01:04:29.613165Z","iopub.status.idle":"2025-11-13T01:04:29.787072Z","shell.execute_reply.started":"2025-11-13T01:04:29.613126Z","shell.execute_reply":"2025-11-13T01:04:29.785889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CODUNI'\nchave_principal = 'PA_CODUNI'\n\n# A chave da nossa tabela auxiliar (estabelecimentos) √© 'CNES'\nchave_auxiliar = 'CNES'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_estabelecimentos[chave_auxiliar] = df_estabelecimentos[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.788308Z","iopub.execute_input":"2025-11-13T01:04:29.788600Z","iopub.status.idle":"2025-11-13T01:04:29.851943Z","shell.execute_reply.started":"2025-11-13T01:04:29.788576Z","shell.execute_reply":"2025-11-13T01:04:29.850618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar o 'NOME FANTASIA' e a 'RAZAO SOCIAL' do estabelecimento\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_estabelecimentos[['CNES', 'FANTASIA', 'RAZ_SOCI']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '2254611')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '2254611')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Estabelecimentos conclu√≠do!\")\n\n# Renomeia as colunas para ficar mais claro\ndf_analise.rename(columns={\n    'FANTASIA': 'NOME_ESTABELECIMENTO',\n    'RAZ_SOCI': 'RAZAO_SOCIAL_ESTAB'\n}, inplace=True)\n\n# Verifica o resultado, mostrando o c√≥digo e os novos nomes\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CODUNI', 'NOME_ESTABELECIMENTO']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:29.853378Z","iopub.execute_input":"2025-11-13T01:04:29.853644Z","iopub.status.idle":"2025-11-13T01:04:30.012070Z","shell.execute_reply.started":"2025-11-13T01:04:29.853621Z","shell.execute_reply":"2025-11-13T01:04:30.010958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CIDPRI'\nchave_principal = 'PA_CIDPRI'\n\n# A chave da nossa tabela auxiliar (CID) √© 'CD_COD'\nchave_auxiliar = 'CD_COD'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_cid[chave_auxiliar] = df_cid[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.013192Z","iopub.execute_input":"2025-11-13T01:04:30.013616Z","iopub.status.idle":"2025-11-13T01:04:30.025392Z","shell.execute_reply.started":"2025-11-13T01:04:30.013584Z","shell.execute_reply":"2025-11-13T01:04:30.024319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar a 'CD_DESCR' (Descri√ß√£o do CID)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_cid[['CD_COD', 'CD_DESCR']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: 'I10')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: 'I10')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Diagn√≥sticos (CID) conclu√≠do!\")\n\n# Renomeia a coluna para ficar mais claro\ndf_analise.rename(columns={'CD_DESCR': 'NOME_DIAGNOSTICO'}, inplace=True)\n\n# Verifica o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CIDPRI', 'NOME_DIAGNOSTICO']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.029153Z","iopub.execute_input":"2025-11-13T01:04:30.029420Z","iopub.status.idle":"2025-11-13T01:04:30.178629Z","shell.execute_reply.started":"2025-11-13T01:04:30.029399Z","shell.execute_reply":"2025-11-13T01:04:30.177702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# A chave da nossa tabela de an√°lise √© 'PA_CBOCOD'\nchave_principal = 'PA_CBOCOD'\n\n# A chave da nossa tabela auxiliar (CBO) √© 'CBO'\nchave_auxiliar = 'CBO'\n\n# Converte ambas as colunas-chave para string (texto)\ndf_analise[chave_principal] = df_analise[chave_principal].astype(str)\ndf_cbo[chave_auxiliar] = df_cbo[chave_auxiliar].astype(str)\n\nprint(f\"Tipos das chaves '{chave_principal}' e '{chave_auxiliar}' corrigidos para string!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.179685Z","iopub.execute_input":"2025-11-13T01:04:30.180064Z","iopub.status.idle":"2025-11-13T01:04:30.190914Z","shell.execute_reply.started":"2025-11-13T01:04:30.180028Z","shell.execute_reply":"2025-11-13T01:04:30.189578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Vamos puxar a 'DS_CBO' (Descri√ß√£o do CBO)\ndf_analise = pd.merge(\n    left=df_analise,\n    right=df_cbo[['CBO', 'DS_CBO']], \n    left_on=chave_principal,    # Chave da tabela principal (ex: '225125')\n    right_on=chave_auxiliar,   # Chave da tabela auxiliar (ex: '225125')\n    how='left'                 # 'left' para n√£o perder nenhum registro\n)\n\nprint(\"Merge com Ocupa√ß√µes (CBO) conclu√≠do!\")\n\n# Renomeia a coluna para ficar mais claro\ndf_analise.rename(columns={'DS_CBO': 'NOME_OCUPACAO'}, inplace=True)\n\n# Verifica o resultado\nprint(\"\\nVerificando as 5 primeiras linhas do resultado:\")\nprint(df_analise[['PA_CBOCOD', 'NOME_OCUPACAO']].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.193091Z","iopub.execute_input":"2025-11-13T01:04:30.193475Z","iopub.status.idle":"2025-11-13T01:04:30.355076Z","shell.execute_reply.started":"2025-11-13T01:04:30.193436Z","shell.execute_reply":"2025-11-13T01:04:30.354053Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# An√°lise em iju√≠","metadata":{}},{"cell_type":"markdown","source":"## Metodologia: Prepara√ß√£o e Enriquecimento dos Dados\nO que foi feito?\n\nO primeiro passo consistiu em processar o conjunto de dados brutos, que continha um volume massivo de 13.210.711 registros de procedimentos ambulatoriais.\n\nPara focar a an√°lise na realidade do munic√≠pio, aplicamos um filtro inicial para isolar apenas os procedimentos realizados em estabelecimentos de sa√∫de localizados em Iju√≠ (c√≥digo IBGE 431020).\n\nDescobertas e Resultados\n\nFiltro de Foco: O universo de an√°lise foi reduzido de **13.2 milh√µes** para **160.060** procedimentos realizados em Iju√≠ durante o per√≠odo analisado.\n\nOtimiza√ß√£o de Mem√≥ria: Esta filtragem foi crucial para a viabilidade da an√°lise, reduzindo o uso de mem√≥ria de **7.4+ GB** para apenas **86.7 MB**, permitindo um processamento r√°pido e eficiente.\n\nEnriquecimento dos Dados: A tabela final foi enriquecida atrav√©s de 5 jun√ß√µes (merges). C√≥digos t√©cnicos (como PA_PROC_ID, PA_MUNPCN, PA_CODUNI, PA_CIDPRI e PA_CBOCOD) foram \"traduzidos\" para informa√ß√µes leg√≠veis, como:\n\n*NOME_PROCEDIMENTO*\n\n*MUNICIPIO_PACIENTE*\n\n*NOME_ESTABELECIMENTO*\n\n*NOME_DIAGNOSTICO*\n\n*NOME_OCUPACAO*","metadata":{}},{"cell_type":"code","source":"# Lista de colunas para remover (quase vazias ou in√∫teis)\ncolunas_para_remover = [\n    'PA_ETNIA',          # Quase vazia (310 registros)\n    'PA_INE',            # Totalmente vazia (0 registros)\n    'PA_SRV_C'           # Mais da metade vazia\n]\n\n# Apaga as colunas\ndf_analise.drop(columns=colunas_para_remover, inplace=True)\n\nprint(\"Colunas 'PA_ETNIA', 'PA_INE', e 'PA_SRV_C' foram removidas.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.356215Z","iopub.execute_input":"2025-11-13T01:04:30.356568Z","iopub.status.idle":"2025-11-13T01:04:30.419598Z","shell.execute_reply.started":"2025-11-13T01:04:30.356536Z","shell.execute_reply":"2025-11-13T01:04:30.418452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Colunas \"inuteis\" removidas, para termos melhor foco no que importa.","metadata":{}},{"cell_type":"markdown","source":"## An√°lise de Fluxo Regional","metadata":{}},{"cell_type":"code","source":"# Mostra os 15 munic√≠pios de pacientes mais frequentes\nprint(\"Top 15 munic√≠pios de resid√™ncia dos pacientes:\")\nprint(df_analise['MUNICIPIO_PACIENTE'].value_counts().head(15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.421105Z","iopub.execute_input":"2025-11-13T01:04:30.421495Z","iopub.status.idle":"2025-11-13T01:04:30.438470Z","shell.execute_reply.started":"2025-11-13T01:04:30.421458Z","shell.execute_reply":"2025-11-13T01:04:30.437422Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analisamos a coluna *MUNICIPIO_PACIENTE* para entender a origem dos pacientes atendidos nos estabelecimentos de Iju√≠. Esta tabela mostra os 15 munic√≠pios de resid√™ncia mais **frequentes**.\n\nDescobertas e Resultados\n\n- **Demanda Mista:** A rede de sa√∫de de Iju√≠ atende a uma demanda quase equilibrada entre moradores locais e pacientes de fora. Iju√≠ (78.559 procedimentos) representa a maior fatia, mas √© seguida de perto por um volume massivo de pacientes de outras cidades.\n\n- **Depend√™ncia Regional:** Munic√≠pios vizinhos como *Panambi (7.529)*, *Joia (5.485)*, *Catu√≠pe (4.524)* e *Augusto Pestana (3.710)* demonstram uma forte depend√™ncia dos servi√ßos de sa√∫de de Iju√≠.\n\nProblema de Qualidade de Dado: Foi identificado um volume significativo de 10.439 registros (cerca de *6,5%* do total) classificados como **\"Invalido\"**.","metadata":{}},{"cell_type":"code","source":"# Cria um novo DataFrame 'df_analise_limpa'\n# que cont√©m APENAS as linhas onde MUNICIPIO_PACIENTE N√ÉO √© 'Invalido'\ndf_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n\nprint(f\"Registros inv√°lidos ('Invalido') removidos.\")\nprint(f\"Total de registros original: {len(df_analise)}\")\nprint(f\"Total de registros limpos para an√°lise: {len(df_analise_limpa)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.439497Z","iopub.execute_input":"2025-11-13T01:04:30.439850Z","iopub.status.idle":"2025-11-13T01:04:30.607009Z","shell.execute_reply.started":"2025-11-13T01:04:30.439816Z","shell.execute_reply":"2025-11-13T01:04:30.605883Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Limpeza desses dados inv√°lidos\n### Compara√ß√£o: Exterior e Interior\n","metadata":{}},{"cell_type":"code","source":"# 1. Conta o total de atendimentos limpos\ntotal_atendimentos = len(df_analise_limpa)\n\n# 2. Conta quantos atendimentos s√£o de pacientes que moram em 'Ijui'\natendimentos_de_ijui = len(df_analise_limpa[df_analise_limpa['MUNICIPIO_PACIENTE'] == 'Ijui'])\n\n# 3. Calcula os de fora\natendimentos_de_fora = total_atendimentos - atendimentos_de_ijui\n\n# 4. Calcula as porcentagens\npct_ijui = (atendimentos_de_ijui / total_atendimentos) * 100\npct_fora = (atendimentos_de_fora / total_atendimentos) * 100\n\n# 5. Mostra o resultado para o gestor\nprint(\"--- üè• An√°lise de Fluxo Regional de Pacientes (Iju√≠) ---\")\nprint(f\"Total de atendimentos analisados: {total_atendimentos}\")\nprint(f\"\\nAtendimentos de pacientes de Iju√≠: {atendimentos_de_ijui} ({pct_ijui:.2f}%)\")\nprint(f\"Atendimentos de pacientes de OUTROS MUNIC√çPIOS: {atendimentos_de_fora} ({pct_fora:.2f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.608348Z","iopub.execute_input":"2025-11-13T01:04:30.608740Z","iopub.status.idle":"2025-11-13T01:04:30.663332Z","shell.execute_reply.started":"2025-11-13T01:04:30.608688Z","shell.execute_reply":"2025-11-13T01:04:30.662136Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Mesmo com essa grande quantidade de dados de pacientes de outros munic√≠pios, Iju√≠ permanece com a maioria dos pacientes atendidos sendo da pr√≥pria cidade.","metadata":{}},{"cell_type":"markdown","source":"### An√°lise de Fluxo Regional: Pacientes Externos","metadata":{}},{"cell_type":"code","source":"# Filtrar o DataFrame para excluir 'Ijui'\ndf_pacientes_de_fora = df_analise_limpa[df_analise_limpa['MUNICIPIO_PACIENTE'] != 'Ijui']\n\n# Contar os munic√≠pios restantes e pegar o Top 10\ntop_10_municipios = df_pacientes_de_fora['MUNICIPIO_PACIENTE'].value_counts().head(10)\n\nprint(\"--- üó∫Ô∏è Top 10 Munic√≠pios de Origem dos Pacientes (Excluindo Iju√≠) ---\")\nprint(top_10_municipios)\n\n# Preparar dados para o gr√°fico\ndf_top_10_chart = top_10_municipios.reset_index()\ndf_top_10_chart.columns = ['Munic√≠pio', 'Total de Atendimentos']\n\nimport altair as alt\n\n# Criar o gr√°fico de barras horizontal\nchart = alt.Chart(df_top_10_chart).mark_bar().encode(\n    # Ordenar pela contagem de atendimentos em ordem decrescente\n    x=alt.X('Total de Atendimentos:Q'),\n    y=alt.Y('Munic√≠pio:N', sort='-x'),\n    tooltip=['Munic√≠pio', 'Total de Atendimentos']\n).properties(\n    title='Top 10 Munic√≠pios de Origem dos Pacientes Atendidos em Iju√≠'\n)\n\n# Salvar o gr√°fico\nchart.save('top_10_municipios_pacientes.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.664492Z","iopub.execute_input":"2025-11-13T01:04:30.664839Z","iopub.status.idle":"2025-11-13T01:04:30.748811Z","shell.execute_reply.started":"2025-11-13T01:04:30.664813Z","shell.execute_reply":"2025-11-13T01:04:30.747841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ap√≥s a remo√ß√£o dos dados *\"Inv√°lidos\"* e dos pr√≥prios moradores de \"Iju√≠\" da base de an√°lise, geramos um ranking dos 10 munic√≠pios que mais encaminham pacientes para a rede de sa√∫de de Iju√≠.\n\nDescobertas e Resultados\n\n- **Depend√™ncia Concentrada:** A an√°lise identifica um grupo claro de munic√≠pios que dependem fortemente de Iju√≠. **Panambi (7.529 procedimentos)** e **Joia (5.485)** s√£o os maiores **\"clientes\"** do sistema.\n\n- **Cintur√£o Regional:** Cidades vizinhas como Catu√≠pe, Augusto Pestana e Condor, somadas a outros polos regionais como Cruz Alta e Santo Augusto, comp√µem um volume expressivo e constante de demanda.\n\n- **Volume Total Externo:** Conforme a an√°lise anterior (Etapa 2), o volume total de pacientes de fora (71.062) √© quase igual ao de moradores locais (78.559).","metadata":{}},{"cell_type":"markdown","source":"# Quais hospitais, UBS e cl√≠nicas mais produzem em Iju√≠? (Produ√ß√£o por Estabelecimento)","metadata":{}},{"cell_type":"code","source":"# --- Etapa 1: Limpar os dados \"Inv√°lidos\" ---\n# (df_analise foi recarregado pela c√©lula anterior)\ndf_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\nprint(f\"Total de registros limpos para an√°lise: {len(df_analise_limpa)}\")\n\n# --- Etapa 2: Executar a An√°lise de Produ√ß√£o por Estabelecimento ---\n# Conta a frequ√™ncia de cada estabelecimento na tabela limpa\nranking_estabelecimentos = df_analise_limpa['NOME_ESTABELECIMENTO'].value_counts().head(10)\n\nprint(\"\\n--- üè• Ranking de Produ√ß√£o por Estabelecimento (Top 10) ---\")\nprint(ranking_estabelecimentos)\n\n# --- Etapa 3: Gerar Gr√°fico ---\nimport altair as alt\n\n# Preparar dados para o gr√°fico\ndf_chart_estab = ranking_estabelecimentos.reset_index()\ndf_chart_estab.columns = ['Estabelecimento', 'N¬∫ de Procedimentos']\n\n# Criar o gr√°fico de barras horizontal\nchart = alt.Chart(df_chart_estab).mark_bar().encode(\n    x=alt.X('N¬∫ de Procedimentos:Q'),\n    y=alt.Y('Estabelecimento:N', sort='-x'), # '-x' ordena do maior para o menor\n    tooltip=['Estabelecimento', 'N¬∫ de Procedimentos']\n).properties(\n    title='Top 10 Estabelecimentos por N¬∫ de Procedimentos em Iju√≠'\n)\n\n# Salvar o gr√°fico\nchart.save('top_10_estabelecimentos.json')\nprint(\"Gr√°fico 'top_10_estabelecimentos.json' salvo.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.749565Z","iopub.execute_input":"2025-11-13T01:04:30.749846Z","iopub.status.idle":"2025-11-13T01:04:30.958011Z","shell.execute_reply.started":"2025-11-13T01:04:30.749824Z","shell.execute_reply":"2025-11-13T01:04:30.956819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A partir da base de dados limpa **(149.621 registros)**, agrupamos os procedimentos pelo NOME_ESTABELECIMENTO para identificar quais locais s√£o respons√°veis pelo maior volume de atendimentos em Iju√≠.\n\nDescobertas e Resultados\n\n- **Domin√¢ncia Hospitalar:** O Hospital de Cl√≠nicas *Iju√≠ (HCI)* √©, disparado, o maior prestador de servi√ßos, com 58.551 procedimentos. Ele √© seguido pelo *Hospital Bom Pastor (26.927)*.\n\n- **For√ßa da Sa√∫de Mental:** A Rede de Aten√ß√£o Psicossocial (RAPS) demonstra uma for√ßa surpreendente. Os tr√™s centros *(CAPS AD, CAPS Infantil e CAPS II) somam 21.076* procedimentos, um volume que rivaliza com o Hospital Bom Pastor.\n\n- **Relev√¢ncia dos Centros Especializados:** *O Centro de Reabilita√ß√£o (CER III UNIR)* com *10.017* procedimentos e o Centro Auditivo (5.504) tamb√©m figuram com destaque.\n\n- **Aten√ß√£o B√°sica vs. Especializada:** A Aten√ß√£o Prim√°ria aparece no ranking representada pelo *Posto Central (4.335)*, mas a lista √© majoritariamente dominada por servi√ßos de m√©dia e alta complexidade.","metadata":{}},{"cell_type":"markdown","source":"## Quais pessoas mais v√£o a estes hospitais? (Perfil Demogr√°fico)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n    print(f\"Total de registros limpos para an√°lise: {len(df_analise_limpa)}\")\n\n    # --- Etapa 2: An√°lise de G√™nero (PA_SEXO) ---\n    print(\"\\n---  demographic An√°lise: G√™nero ---\")\n    \n    # Mapear os c√≥digos para nomes leg√≠veis (M=Masculino, F=Feminino)\n    df_analise_limpa['GENERO'] = df_analise_limpa['PA_SEXO'].map({'M': 'Masculino', 'F': 'Feminino', 'I': 'Ignorado'})\n    \n    # Contar os valores e calcular a porcentagem\n    dist_genero = df_analise_limpa['GENERO'].value_counts()\n    dist_genero_pct = df_analise_limpa['GENERO'].value_counts(normalize=True) * 100\n    \n    print(\"Distribui√ß√£o por G√™nero:\")\n    print(dist_genero)\n    print(\"\\nDistribui√ß√£o Percentual por G√™nero:\")\n    print(dist_genero_pct.round(2))\n\n    # --- Etapa 3: An√°lise de Idade (PA_IDADE) ---\n    print(\"\\n---  demographic An√°lise: Idade ---\")\n    \n    # A coluna PA_IDADE no SIASUS √© em ANOS.\n    print(\"Estat√≠sticas Descritivas da Idade:\")\n    print(df_analise_limpa['PA_IDADE'].describe().round(2))\n\n    # Criar faixas et√°rias (bins)\n    bins = [-1, 9, 19, 29, 39, 49, 59, 69, 79, 130]\n    labels = ['0-9 anos', '10-19 anos', '20-29 anos', '30-39 anos', '40-49 anos', '50-59 anos', '60-69 anos', '70-79 anos', '80+ anos']\n    \n    df_analise_limpa['FAIXA_ETARIA'] = pd.cut(df_analise_limpa['PA_IDADE'], bins=bins, labels=labels, right=True)\n    \n    # Contar os valores em cada faixa et√°ria\n    dist_faixa_etaria = df_analise_limpa['FAIXA_ETARIA'].value_counts().sort_index()\n    \n    print(\"\\nDistribui√ß√£o por Faixa Et√°ria:\")\n    print(dist_faixa_etaria)\n\n    # --- Etapa 4: Gerar Gr√°fico de Faixa Et√°ria ---\n    \n    # Preparar dados para o gr√°fico\n    df_chart_idade = dist_faixa_etaria.reset_index()\n    df_chart_idade.columns = ['Faixa Et√°ria', 'N¬∫ de Procedimentos']\n\n    # Criar o gr√°fico de barras\n    chart = alt.Chart(df_chart_idade).mark_bar().encode(\n        x=alt.X('Faixa Et√°ria:N', sort=None), # 'sort=None' mant√©m a ordem dos labels\n        y=alt.Y('N¬∫ de Procedimentos:Q'),\n        tooltip=['Faixa Et√°ria', 'N¬∫ de Procedimentos']\n    ).properties(\n        title='Distribui√ß√£o de Procedimentos por Faixa Et√°ria em Iju√≠'\n    )\n\n    # Salvar o gr√°fico\n    chart.save('distribuicao_faixa_etaria.json')\n    print(\"\\nGr√°fico 'distribuicao_faixa_etaria.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:30.959077Z","iopub.execute_input":"2025-11-13T01:04:30.959393Z","iopub.status.idle":"2025-11-13T01:04:31.199804Z","shell.execute_reply.started":"2025-11-13T01:04:30.959367Z","shell.execute_reply":"2025-11-13T01:04:31.198782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analisamos as colunas *PA_SEXO (G√™nero)* e *PA_IDADE (Idade)* da nossa base de dados limpa (149.621 registros) para entender o perfil demogr√°fico da popula√ß√£o atendida. A idade foi agrupada em faixas de 10 anos para identificar os grupos de maior demanda.\n\nDescobertas e Resultados\n\n- **G√™nero:** A distribui√ß√£o de atendimentos √© quase perfeitamente equilibrada entre os g√™neros, com 50,38% Masculino (75.384) e 49,62% Feminino (74.237).\n\n- **Idade M√©dia vs. Mediana:** A idade m√©dia dos pacientes √© de 52 anos. No entanto, a idade mediana (o valor do meio) √© de 58 anos, indicando que a maioria dos pacientes est√° na metade mais velha da popula√ß√£o.\n\n- **Pico de Demanda no Envelhecimento:** A distribui√ß√£o por faixa et√°ria (visualizada no gr√°fico distribuicao_faixa_etaria.json) mostra um aumento dr√°stico na demanda a partir dos 50 anos. O pico de atendimentos ocorre na faixa dos 60-69 anos (33.791 procedimentos).\n\n- **Impacto da Popula√ß√£o 60+:** Somando as faixas et√°rias de 60 anos ou mais (60-69, 70-79 e 80+), este grupo sozinho representa 70.295 procedimentos, o que equivale a 47% de todos os atendimentos realizados.","metadata":{}},{"cell_type":"markdown","source":"## Epidemiol√≥gica: os principais diagn√≥sticos (CID)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: An√°lise dos Principais Diagn√≥sticos (CID) ---\n    print(\"\\n--- ü©∫ An√°lise: Top 10 Principais Diagn√≥sticos (CID) ---\")\n    \n    # O .value_counts() automaticamente conta os valores mais frequentes\n    # e ignora os diagn√≥sticos nulos (NaN)\n    top_10_diagnosticos = df_analise_limpa['NOME_DIAGNOSTICO'].value_counts().head(10)\n    \n    print(\"Top 10 diagn√≥sticos mais frequentes em Iju√≠:\")\n    print(top_10_diagnosticos)\n\n    # --- Etapa 3: Gerar Gr√°fico ---\n    \n    # Preparar dados para o gr√°fico\n    df_chart_diag = top_10_diagnosticos.reset_index()\n    df_chart_diag.columns = ['Diagn√≥stico', 'N¬∫ de Procedimentos']\n\n    # Criar o gr√°fico de barras horizontal\n    chart = alt.Chart(df_chart_diag).mark_bar().encode(\n        x=alt.X('N¬∫ de Procedimentos:Q'),\n        y=alt.Y('Diagn√≥stico:N', sort='-x'), # '-x' ordena do maior para o menor\n        tooltip=['Diagn√≥stico', 'N¬∫ de Procedimentos']\n    ).properties(\n        title='Top 10 Diagn√≥sticos (CID) Mais Frequentes em Iju√≠'\n    )\n\n    # Salvar o gr√°fico\n    chart.save('top_10_diagnosticos.json')\n    print(\"\\nGr√°fico 'top_10_diagnosticos.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:31.201191Z","iopub.execute_input":"2025-11-13T01:04:31.201547Z","iopub.status.idle":"2025-11-13T01:04:31.395786Z","shell.execute_reply.started":"2025-11-13T01:04:31.201521Z","shell.execute_reply":"2025-11-13T01:04:31.394753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analisamos a coluna *NOME_DIAGNOSTICO* para identificar os 10 principais diagn√≥sticos (CID) registrados nos atendimentos em Iju√≠.\n\nDescobertas e Resultados\n\nAlerta de Qualidade de Dados: A descoberta mais impactante √© que o diagn√≥stico mais \"comum\" √© \"CID NAO INFORMADO\", com 89.693 registros. Isso representa 60% de toda a nossa base de dados limpa (149.621 registros).\n\n**Doen√ßas Cr√¥nicas (Alto Custo):** O diagn√≥stico real mais frequente √© *Doen√ßa Renal em Est√°gio Final (N18.0)*, com *6.792* registros. Isso indica uma alta demanda por terapias de alto custo, como hemodi√°lise.\n\n**Servi√ßos Especializados:** *Perda de Audi√ß√£o (H90.5)*, com *5.075* registros, e *Transtornos de Desenvolvimento/Autismo (F84.x)*, com *4.456* registros (somando F84.9 e F84.0), aparecem com destaque.\n\n**Doen√ßas Cr√¥nicas (Popula√ß√£o):** *Doen√ßa Cardiovascular (I51.6)* e *C√¢ncer (C50.0 - Mamilo e ar√©ola)* tamb√©m est√£o no top 10, alinhados com o perfil de envelhecimento da popula√ß√£o que vimos anteriormente.","metadata":{}},{"cell_type":"markdown","source":"## Volume vs. An√°lise Financeira","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: An√°lise de VOLUME (Procedimentos Mais Frequentes) ---\n    print(\"\\n--- üìà An√°lise de VOLUME: Top 10 Procedimentos Mais Realizados ---\")\n    \n    # .value_counts() na coluna de nome do procedimento\n    top_10_volume = df_analise_limpa['NOME_PROCEDIMENTO'].value_counts().head(10)\n    \n    print(top_10_volume)\n\n    # --- Etapa 3: An√°lise FINANCEIRA (Procedimentos Mais Rent√°veis) ---\n    print(\"\\n--- üí∞ An√°lise FINANCEIRA: Top 10 Procedimentos por Valor Aprovado ---\")\n    \n    # Agrupamos por nome do procedimento e SOMAMOS o valor aprovado\n    # PA_VALAPR = Valor Aprovado\n    top_10_financeiro = df_analise_limpa.groupby('NOME_PROCEDIMENTO')['PA_VALAPR'].sum().sort_values(ascending=False).head(10)\n    \n    # Formata para Reais (R$) para ficar mais leg√≠vel\n    print(top_10_financeiro.apply(lambda x: f\"R$ {x:,.2f}\"))\n\n    # --- Etapa 4: Gerar Gr√°fico (Financeiro) ---\n    \n    # Preparar dados para o gr√°fico\n    df_chart_fin = top_10_financeiro.reset_index()\n    df_chart_fin.columns = ['Procedimento', 'Valor Total Aprovado']\n\n    # Criar o gr√°fico de barras horizontal\n    chart = alt.Chart(df_chart_fin).mark_bar().encode(\n        x=alt.X('Valor Total Aprovado:Q'),\n        y=alt.Y('Procedimento:N', sort='-x'), # '-x' ordena do maior para o menor\n        tooltip=['Procedimento', alt.Tooltip('Valor Total Aprovado:Q', format='$,.2f')]\n    ).properties(\n        title='Top 10 Procedimentos por Receita (Valor Aprovado) em Iju√≠'\n    )\n\n    # Salvar o gr√°fico\n    chart.save('top_10_procedimentos_financeiro.json')\n    print(\"\\nGr√°fico 'top_10_procedimentos_financeiro.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:31.396897Z","iopub.execute_input":"2025-11-13T01:04:31.397277Z","iopub.status.idle":"2025-11-13T01:04:31.616877Z","shell.execute_reply.started":"2025-11-13T01:04:31.397236Z","shell.execute_reply":"2025-11-13T01:04:31.615809Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Realizamos duas an√°lises distintas sobre os procedimentos:\n\n1. **An√°lise de Volume:** Contamos a frequ√™ncia de cada procedimento *(NOME_PROCEDIMENTO)* para ver quais s√£o os mais comuns (Top 10 mais realizados).\n\n2. **An√°lise Financeira:** Somamos o valor aprovado *(PA_VALAPR)* de cada procedimento para ver quais geram maior receita/custo (Top 10 mais rent√°veis).\n\nDescobertas e Resultados\n\nAn√°lise de Volume (Os Mais Comuns):\n\n**Consultas:** O dia a dia do sistema √© dominado por consultas. *Consulta M√©dica Especializada (18.429)* e *Consulta de N√≠vel Superior (N√£o-M√©dico) (18.369)* s√£o os procedimentos mais realizados, somando quase *37.000* atendimentos.\n\n**Sa√∫de Mental e Reabilita√ß√£o:** Conforme visto nos rankings anteriores, os atendimentos em CAPS (reabilita√ß√£o psicossocial, atendimento individual/grupo) e de Reabilita√ß√£o (neuropsicomotor, m√∫ltiplas defici√™ncias) dominam a lista, ocupando 6 das 10 posi√ß√µes.\n\nAn√°lise Financeira (Os Mais Rent√°veis):\n\n**A Desconex√£o:** A descoberta mais importante √© que nenhum dos procedimentos mais comuns (volume) aparece na lista dos mais rent√°veis (financeiro).\n\n**Terapia Renal (Nefrologia):** A *Hemodi√°lise* √©, isoladamente, o procedimento de maior impacto financeiro, gerando *R$ 1,16 Milh√£o* em receita/custo.\n\n**Medicamentos de Alto Custo:** V√°rios dos itens mais caros s√£o medicamentos especializados, como *Mepolizumabe (R$ 513 mil)* e *Omalizumabe (R$ 449 mil).*\n\n**Oncologia e Alta Complexidade:** *Quimioterapia*, *Radioterapia* e *Cateterismo Card√≠aco* completam a lista, confirmando que a alta complexidade domina o or√ßamento.","metadata":{}},{"cell_type":"markdown","source":"# An√°lise de Evolu√ß√£o Temporal","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: Preparar a Coluna de Data (PA_CMP) ---\n    \n    # Converte a coluna 'PA_CMP' (ex: 202501) para um formato de Data (ex: 2025-01-01)\n    # Isso nos permite agrupar por m√™s/ano\n    df_analise_limpa['DATA_COMPETENCIA'] = pd.to_datetime(df_analise_limpa['PA_CMP'], format='%Y%m')\n    \n    print(\"Coluna de data (PA_CMP) convertida.\")\n\n    # --- Etapa 3: Agrupar por M√™s (An√°lise Temporal) ---\n    print(\"\\n--- üìÖ An√°lise de Evolu√ß√£o Temporal (Volume e Valor) ---\")\n    \n    # Agrupa pela data, contando o n√∫mero de procedimentos (size)\n    # e somando o valor aprovado (PA_VALAPR)\n    df_temporal = df_analise_limpa.groupby('DATA_COMPETENCIA').agg(\n        TOTAL_PROCEDIMENTOS=('PA_CMP', 'size'),\n        TOTAL_VALOR_APROVADO=('PA_VALAPR', 'sum')\n    ).reset_index()\n    \n    # Formata o valor para Reais (R$)\n    df_temporal['TOTAL_VALOR_APROVADO_R$'] = df_temporal['TOTAL_VALOR_APROVADO'].apply(lambda x: f\"R$ {x:,.2f}\")\n    \n    print(\"Evolu√ß√£o m√™s a m√™s:\")\n    print(df_temporal[['DATA_COMPETENCIA', 'TOTAL_PROCEDIMENTOS', 'TOTAL_VALOR_APROVADO_R$']])\n\n    # --- Etapa 4: Gerar Gr√°fico de Linha (Evolu√ß√£o) ---\n    \n    # O Altair lida melhor com o formato \"longo\" de dados. Vamos \"derreter\" (melt) a tabela.\n    df_chart_temporal = df_temporal.melt(\n        id_vars=['DATA_COMPETENCIA'], \n        value_vars=['TOTAL_PROCEDIMENTOS', 'TOTAL_VALOR_APROVADO'],\n        var_name='Metrica', \n        value_name='Valor'\n    )\n\n    # Cria o gr√°fico de linha\n    chart = alt.Chart(df_chart_temporal).mark_line(point=True).encode(\n        x=alt.X('DATA_COMPETENCIA:T', axis=alt.Axis(title='M√™s', format='%Y-%m')),\n        y=alt.Y('Valor:Q'),\n        color='Metrica:N', # Uma cor para Procedimentos, outra para Valor\n        tooltip=['DATA_COMPETENCIA:T', 'Metrica:N', 'Valor:Q']\n    ).properties(\n        title='Evolu√ß√£o de Procedimentos vs. Valor Aprovado'\n    ).interactive() # Permite zoom e pan\n\n    # Salvar o gr√°fico\n    chart.save('evolucao_temporal.json')\n    print(\"\\nGr√°fico 'evolucao_temporal.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciado).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:31.618042Z","iopub.execute_input":"2025-11-13T01:04:31.618337Z","iopub.status.idle":"2025-11-13T01:04:31.856878Z","shell.execute_reply.started":"2025-11-13T01:04:31.618313Z","shell.execute_reply":"2025-11-13T01:04:31.855749Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analisamos a evolu√ß√£o da produ√ß√£o ao longo do tempo. Para isso, a coluna de compet√™ncia (*PA_CMP*, que estava em formato de texto como *202501*) foi convertida para um formato de data. Isso permitiu agrupar todos os *149.621* procedimentos por m√™s, somando o Volume Total de Procedimentos e o Valor Total Aprovado (R$) para cada per√≠odo.\n\nDescobertas e Resultados\n\n- **Meses de An√°lise (Picos):** A an√°lise confirma que os dados de produ√ß√£o est√£o concentrados em tr√™s meses principais:\n\n1. **Janeiro/2025:** *48.803* procedimentos *(R$ 3,67 milh√µes)*\n\n2. **Maio/2025:** *48.983* procedimentos *(R$ 3,49 milh√µes)*\n\n3. **Agosto/2025:** *51.593* procedimentos *(R$ 3,97 milh√µes)*\n\n- **Tend√™ncia de Crescimento:** Observa-se uma leve, mas consistente, tend√™ncia de aumento no volume de atendimentos e no custo financeiro ao longo dos meses analisados, com Agosto apresentando os maiores n√∫meros.\n\n- **Registros Residuais (\"Ajustes\"):** Os outros meses que aparecem na tabela (ex: *Out/2024, Dez/2024, Jun/2025*) possuem valores irris√≥rios (ex: *9, 33, 79 procedimentos*). Isso √© normal e representa *\"ajustes de compet√™ncia\"* ‚Äì registros que foram processados nos arquivos de *Jan/Mai/Ago*, mas se referiam a datas passadas. Eles n√£o representam a produ√ß√£o real daqueles meses e foram ignorados na an√°lise de tend√™ncia.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter # Importa o formatador\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: Preparar a Coluna de Data (PA_CMP) ---\n    df_analise_limpa['DATA_COMPETENCIA'] = pd.to_datetime(df_analise_limpa['PA_CMP'], format='%Y%m')\n    print(\"Coluna de data (PA_CMP) convertida.\")\n\n    # --- Etapa 3: Agrupar por M√™s (Focando no Valor Financeiro) ---\n    df_temporal_financeiro = df_analise_limpa.groupby('DATA_COMPETENCIA').agg(\n        TOTAL_VALOR_APROVADO=('PA_VALAPR', 'sum')\n    ).reset_index()\n\n    # Para o Seaborn, √© mais f√°cil se convertermos a data para string (ex: '2025-01')\n    df_temporal_financeiro['MES_ANO'] = df_temporal_financeiro['DATA_COMPETENCIA'].dt.strftime('%Y-%m')\n    \n    print(\"\\nEvolu√ß√£o m√™s a m√™s (Valor Aprovado):\")\n    print(df_temporal_financeiro[['MES_ANO', 'TOTAL_VALOR_APROVADO']])\n\n    # --- Etapa 4: Gerar Gr√°fico com Seaborn ---\n    print(\"\\nGerando gr√°fico com Seaborn...\")\n    \n    # Configura o tamanho da figura (largura, altura)\n    plt.figure(figsize=(12, 7))\n    \n    # Cria o gr√°fico de barras\n    ax = sns.barplot(\n        data=df_temporal_financeiro,\n        x='MES_ANO',\n        y='TOTAL_VALOR_APROVADO',\n        palette='viridis' # Define uma paleta de cores\n    )\n    \n    # Fun√ß√£o para formatar o eixo Y em Reais (R$ Milh√µes)\n    def format_reais(x, pos):\n        'Retorna o valor formatado como R$ 1.5 M'\n        return f'R$ {x/1e6:.1f} M'\n    \n    # Aplica o formatador no eixo Y\n    ax.yaxis.set_major_formatter(FuncFormatter(format_reais))\n    \n    # Adiciona t√≠tulos e labels\n    plt.title('Evolu√ß√£o Financeira (Valor Aprovado) por M√™s em Iju√≠', fontsize=16)\n    plt.xlabel('M√™s (Ano-M√™s)', fontsize=12)\n    plt.ylabel('Valor Total Aprovado (R$)', fontsize=12)\n    \n    # Rotaciona os labels do eixo X para n√£o sobrepor\n    plt.xticks(rotation=45)\n    \n    # Ajusta o layout para n√£o cortar os labels\n    plt.tight_layout()\n    \n    # Salvar o gr√°fico (como imagem PNG)\n    plt.savefig('evolucao_financeira_seaborn.png')\n    print(\"Gr√°fico 'evolucao_financeira_seaborn.png' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:31.858500Z","iopub.execute_input":"2025-11-13T01:04:31.858864Z","iopub.status.idle":"2025-11-13T01:04:32.556351Z","shell.execute_reply.started":"2025-11-13T01:04:31.858832Z","shell.execute_reply":"2025-11-13T01:04:32.555116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Aqui fizemos um gr√°fico para melhorar a visualiza√ß√£o","metadata":{}},{"cell_type":"markdown","source":"## Foco em √Åreas Cr√≠ticas\nRealizamos um filtro na base de dados limpa (149.621 registros) para isolar todos os procedimentos relacionados √† Sa√∫de Mental, usando palavras-chave como \"Psiquiatria\", \"Psicologia\", \"Psicossocial\", etc.\n- Oncologia: quimioterapia e radioterapia (aprovados x produzidos).\n- Sa√∫de mental: atendimentos psiqui√°tricos e psicol√≥gicos.\n- Aten√ß√£o b√°sica: consultas e procedimentos nas UBS, acompanhamento de doen√ßas cr√¥nicas.\n\n### Sa√∫de Mental:\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: Definir Palavras-Chave e Filtrar ---\n    \n    # Lista de termos para procurar (n√£o diferencia mai√∫sculas/min√∫sculas)\n    keywords_saude_mental = [\n        'PSIQUIATRIA', \n        'PSICOLOGIA', \n        'PSICOLOGO',\n        'PSICOSSOCIAL', \n        'SAUDE MENTAL'\n    ]\n    \n    # Cria o padr√£o de busca (ex: 'PSIQUIATRIA|PSICOLOGIA|...')\n    pattern_saude_mental = '|'.join(keywords_saude_mental)\n    \n    print(f\"Filtrando procedimentos por palavras-chave: {pattern_saude_mental}\")\n\n    # Filtra a coluna 'NOME_PROCEDIMENTO' usando o padr√£o\n    # 'case=False' ignora mai√∫sculas/min√∫sculas\n    # 'na=False' ignora valores nulos sem dar erro\n    df_saude_mental = df_analise_limpa[\n        df_analise_limpa['NOME_PROCEDIMENTO'].str.contains(pattern_saude_mental, case=False, na=False)\n    ].copy()\n\n    print(f\"\\nTotal de {len(df_saude_mental)} procedimentos de Sa√∫de Mental encontrados.\")\n\n    # --- Etapa 3: An√°lise dos Procedimentos de Sa√∫de Mental ---\n    \n    # An√°lise de Volume: Quais os procedimentos mais comuns?\n    print(\"\\n--- üß† An√°lise: Top 10 Procedimentos de Sa√∫de Mental (Volume) ---\")\n    top_10_sm_volume = df_saude_mental['NOME_PROCEDIMENTO'].value_counts().head(10)\n    print(top_10_sm_volume)\n    \n    # An√°lise Financeira: Qual o valor total?\n    total_valor_sm = df_saude_mental['PA_VALAPR'].sum()\n    print(f\"\\nValor Total Aprovado para Sa√∫de Mental: R$ {total_valor_sm:,.2f}\")\n\n    # --- Etapa 4: Gerar Gr√°fico ---\n    \n    # Preparar dados para o gr√°fico\n    df_chart_sm = top_10_sm_volume.reset_index()\n    df_chart_sm.columns = ['Procedimento', 'N¬∫ de Atendimentos']\n\n    # Criar o gr√°fico de barras horizontal\n    chart = alt.Chart(df_chart_sm).mark_bar().encode(\n        x=alt.X('N¬∫ de Atendimentos:Q'),\n        y=alt.Y('Procedimento:N', sort='-x'),\n        tooltip=['Procedimento', 'N¬∫ de Atendimentos']\n    ).properties(\n        title='Top 10 Procedimentos de Sa√∫de Mental em Iju√≠'\n    )\n\n    # Salvar o gr√°fico\n    chart.save('top_10_saude_mental.json')\n    print(\"\\nGr√°fico 'top_10_saude_mental.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:32.557444Z","iopub.execute_input":"2025-11-13T01:04:32.557751Z","iopub.status.idle":"2025-11-13T01:04:33.531309Z","shell.execute_reply.started":"2025-11-13T01:04:32.557727Z","shell.execute_reply":"2025-11-13T01:04:33.530491Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Descobertas e Resultados\n\n- **Volume Massivo:** A Sa√∫de Mental √© uma das √°reas de maior volume em Iju√≠, respondendo por *19.947* procedimentos no per√≠odo analisado (cerca de *13.3%* de todos os atendimentos).\n\n- **Foco no CAPS:** O Top 10 de procedimentos mostra que o atendimento √© totalmente centrado nos Centros de *Aten√ß√£o Psicossocial (CAPS)*. As atividades principais s√£o \"*A√ß√µes de reabilita√ß√£o psicossocial*\" *(5.112)*, \"*Atendimento individual*\" *(4.679)* e \"*Atendimento em grupo*\" *(3.333)*.\n\n- **Descoberta Financeira Chave:** O Valor Total Aprovado *(PA_VALAPR)* para todos os *19.947* procedimentos foi de *R$ 0,00*.","metadata":{}},{"cell_type":"markdown","source":"### Oncologia","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' (caso o kernel tenha reiniciado) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    print(\"DataFrame 'df_analise_limpa' recriado com sucesso.\")\n\n    # --- Etapa 2: Definir Palavras-Chave e Filtrar ---\n    \n    # Lista de termos para procurar\n    keywords_oncologia = [\n        'QUIMIOTERAPIA', \n        'RADIOTERAPIA', \n        'ONCOLOGIA',\n        'ONCOLOGICO'\n    ]\n    \n    # Cria o padr√£o de busca\n    pattern_oncologia = '|'.join(keywords_oncologia)\n    \n    print(f\"Filtrando procedimentos por palavras-chave: {pattern_oncologia}\")\n\n    # Filtra a coluna 'NOME_PROCEDIMENTO'\n    df_oncologia = df_analise_limpa[\n        df_analise_limpa['NOME_PROCEDIMENTO'].str.contains(pattern_oncologia, case=False, na=False)\n    ].copy()\n\n    print(f\"\\nTotal de {len(df_oncologia)} procedimentos de Oncologia encontrados.\")\n\n    # --- Etapa 3: An√°lise dos Procedimentos de Oncologia ---\n    \n    # An√°lise de Volume: Quais os procedimentos mais comuns?\n    print(\"\\n--- üéóÔ∏è An√°lise: Top 10 Procedimentos de Oncologia (Volume) ---\")\n    top_10_onco_volume = df_oncologia['NOME_PROCEDIMENTO'].value_counts().head(10)\n    print(top_10_onco_volume)\n    \n    # An√°lise Financeira: Qual o valor total?\n    total_valor_onco = df_oncologia['PA_VALAPR'].sum()\n    print(f\"\\nValor Total Aprovado para Oncologia: R$ {total_valor_onco:,.2f}\")\n\n    # --- Etapa 4: An√°lise Aprovado vs. Produzido (Item 6 Espec√≠fico) ---\n    print(\"\\n--- üìä An√°lise: Quantidade Aprovada vs. Produzida (Oncologia) ---\")\n    \n    # Soma o total das colunas de quantidade\n    total_produzido = df_oncologia['PA_QTDPRO'].sum()\n    total_aprovado = df_oncologia['PA_QTDAPR'].sum()\n    \n    print(f\"Total de Quantidade Produzida: {total_produzido:,.0f}\")\n    print(f\"Total de Quantidade Aprovada: {total_aprovado:,.0f}\")\n    \n    if total_produzido > 0:\n        taxa_aprovacao = (total_aprovado / total_produzido) * 100\n        print(f\"Taxa de Aprova√ß√£o (Qtd Aprovada / Qtd Produzida): {taxa_aprovacao:.2f}%\")\n\n    # --- Etapa 5: Gerar Gr√°fico (Top 10 Volume) ---\n    \n    df_chart_onco = top_10_onco_volume.reset_index()\n    df_chart_onco.columns = ['Procedimento', 'N¬∫ de Atendimentos']\n\n    chart = alt.Chart(df_chart_onco).mark_bar().encode(\n        x=alt.X('N¬∫ de Atendimentos:Q'),\n        y=alt.Y('Procedimento:N', sort='-x'),\n        tooltip=['Procedimento', 'N¬∫ de Atendimentos']\n    ).properties(\n        title='Top 10 Procedimentos de Oncologia em Iju√≠ (por Volume)'\n    )\n\n    chart.save('top_10_oncologia.json')\n    print(\"\\nGr√°fico 'top_10_oncologia.json' salvo.\")\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recriar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:33.532544Z","iopub.execute_input":"2025-11-13T01:04:33.532870Z","iopub.status.idle":"2025-11-13T01:04:34.119500Z","shell.execute_reply.started":"2025-11-13T01:04:33.532834Z","shell.execute_reply":"2025-11-13T01:04:34.118292Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Filtramos a base de dados limpa *(149.621 registros)* para isolar todos os procedimentos de Oncologia, usando palavras-chave como \"*Quimioterapia*\", \"*Radioterapia*\" e \"*Oncologia*\". Analisamos o volume, o valor financeiro e a taxa de aprova√ß√£o (*produzido vs. aprovado*).\n\nDescobertas e Resultados\n\n- **Alto Custo**, **Baixo Volume**: A *Oncologia* √© uma √°rea de \"*alto custo, baixo volume*\". Foram encontrados *2.567* procedimentos (apenas *1,7%* do volume total de Iju√≠), mas que geraram um custo/receita massivo de *R$ 3,82 milh√µes*.\n\n- **Foco em C√¢nceres Espec√≠ficos:** O ranking de procedimentos √© altamente especializado, com foco em *C√¢ncer de Pr√≥stata*, *Doen√ßas Mieloproliferativas (leucemia)* e *C√¢ncer de C√≥lon/Reto*.\n\n- **Efici√™ncia na Aprova√ß√£o:** A an√°lise de *Quantidade Produzida (2.326) vs. Aprovada (2.322)* revela uma taxa de aprova√ß√£o de *99,83%.*","metadata":{}},{"cell_type":"markdown","source":"### Tend√™ncias de Aumento (Imacto do Envelhecimento)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport altair as alt\n\ntry:\n    # --- Etapa 1: Recriar 'df_analise_limpa' e COLUNA DE IDADE (caso reinicie) ---\n    df_analise_limpa = df_analise[df_analise['MUNICIPIO_PACIENTE'] != 'Invalido'].copy()\n    \n    # Recria as faixas et√°rias (ESSENCIAL para esta an√°lise)\n    bins = [-1, 9, 19, 29, 39, 49, 59, 69, 79, 130]\n    labels = ['0-9 anos', '10-19 anos', '20-29 anos', '30-39 anos', '40-49 anos', '50-59 anos', '60-69 anos', '70-79 anos', '80+ anos']\n    df_analise_limpa['FAIXA_ETARIA'] = pd.cut(df_analise_limpa['PA_IDADE'], bins=bins, labels=labels, right=True)\n    \n    print(\"DataFrame 'df_analise_limpa' e 'FAIXA_ETARIA' recriados.\")\n\n    # --- Etapa 2: Filtrar Procedimentos de CARDIOLOGIA ---\n    keywords_cardio = [\n        'CARDIO', \n        'CARDIOLOGIA', \n        'CARDIOLOGICO', \n        'HEMODINAMICA', \n        'CATETERISMO'\n    ]\n    pattern_cardio = '|'.join(keywords_cardio)\n    \n    df_cardio = df_analise_limpa[\n        df_analise_limpa['NOME_PROCEDIMENTO'].str.contains(pattern_cardio, case=False, na=False)\n    ].copy()\n    \n    print(f\"\\nEncontrados {len(df_cardio)} procedimentos de Cardiologia.\")\n\n    # --- Etapa 3: Filtrar Procedimentos de ONCOLOGIA ---\n    keywords_onco = ['QUIMIOTERAPIA', 'RADIOTERAPIA', 'ONCOLOGIA', 'ONCOLOGICO']\n    pattern_onco = '|'.join(keywords_onco)\n    \n    df_oncologia = df_analise_limpa[\n        df_analise_limpa['NOME_PROCEDIMENTO'].str.contains(pattern_onco, case=False, na=False)\n    ].copy()\n    \n    print(f\"Encontrados {len(df_oncologia)} procedimentos de Oncologia.\")\n\n    # --- Etapa 4: An√°lise da Distribui√ß√£o Et√°ria ---\n    print(\"\\n--- üìä Distribui√ß√£o Percentual por Faixa Et√°ria ---\")\n    \n    # normalize=True calcula a porcentagem (ex: 0.25)\n    # .sort_index() mant√©m a ordem das faixas (0-9, 10-19...)\n    \n    # An√°lise de Cardiologia\n    print(\"\\nü©∫ CARDIOLOGIA (% por Faixa Et√°ria):\")\n    dist_cardio_idade = (df_cardio['FAIXA_ETARIA'].value_counts(normalize=True).sort_index() * 100).round(2)\n    print(dist_cardio_idade)\n    \n    # An√°lise de Oncologia\n    print(\"\\nüéóÔ∏è ONCOLOGIA (% por Faixa Et√°ria):\")\n    dist_onco_idade = (df_oncologia['FAIXA_ETARIA'].value_counts(normalize=True).sort_index() * 100).round(2)\n    print(dist_onco_idade)\n\nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"N√£o consigo encontrar o DataFrame 'df_analise'.\")\n    print(\"Por favor, rode novamente a c√©lula de c√≥digo 'üöÄ C√≥digo Principal (Foco em Iju√≠...)' para recarregar os dados.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:34.120734Z","iopub.execute_input":"2025-11-13T01:04:34.121102Z","iopub.status.idle":"2025-11-13T01:04:35.189508Z","shell.execute_reply.started":"2025-11-13T01:04:34.121066Z","shell.execute_reply":"2025-11-13T01:04:35.188618Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Conforme solicitado no Item 6 do trabalho, cruzamos os dados para verificar o impacto do envelhecimento populacional em √°reas de alto custo. Filtramos a base de dados limpa (*149.621 registros*) para isolar todos os procedimentos de *Cardiologia* e *Oncologia*. Em seguida, analisamos a distribui√ß√£o percentual desses atendimentos por *FAIXA_ETARIA*.\n\nDescobertas e Resultados\n\n- **Concentra√ß√£o Extrema:** A descoberta √© inequ√≠voca. A demanda por estas especialidades de alto custo est√° esmagadoramente concentrada na popula√ß√£o mais velha.\n\n- **Cardiologia:** *83%* de todos os *3.270* procedimentos de cardiologia foram realizados em pacientes com 50 anos ou mais. O pico de demanda ocorre na faixa dos *60-69* anos *(31,13%)*.\n\n- **Oncologia:** O padr√£o √© id√™ntico. *83,6%* de todos os *2.567* procedimentos oncol√≥gicos foram para pacientes com 50 anos ou mais. O pico tamb√©m ocorre na faixa dos *60-69* anos *(29,92%)*.","metadata":{}},{"cell_type":"markdown","source":"## Compara√ß√£o de Iju√≠ com Cruz Alta e Santa Rosa","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n\ntry:\n    print(\"--- üìä Item 7: Iniciando An√°lise Comparativa Regional ---\")\n    \n    # --- Etapa 1: Definir os c√≥digos das cidades-alvo ---\n    # Precisamos dos c√≥digos como N√öMEROS (int),\n    # pois a coluna PA_UFMUN √© int64\n    \n    # (O c√≥digo de Iju√≠ j√° est√° na mem√≥ria como 'codigo_ijui_int',\n    # mas vamos redefini-lo aqui para garantir)\n    \n    codigos_cidades = {\n        'Ijui': 431020,\n        'Santa Rosa': 431720,\n        'Cruz Alta': 430610\n    }\n    \n    # Lista de c√≥digos como n√∫meros para o filtro\n    lista_codigos_int = list(codigos_cidades.values())\n    \n    # --- Etapa 2: Ler os arquivos grandes em \"Peda√ßos\" (Chunks) ---\n    \n    arquivos_producao = [\n        base_path + 'PARS2501.csv',\n        base_path + 'PARS2505.csv',\n        base_path + 'PARS2508.csv'\n    ]\n    \n    lista_chunks_regional = []\n    \n    print(\"Iniciando leitura otimizada (foco em Iju√≠, Sta. Rosa, Cruz Alta)...\")\n    \n    for arquivo in arquivos_producao:\n        print(f\"Processando arquivo: {arquivo}\")\n        \n        with pd.read_csv(arquivo, encoding='latin1', low_memory=False, chunksize=500000) as reader:\n            for chunk in reader:\n                # Filtra o peda√ßo (chunk) para pegar APENAS as linhas\n                # das 3 cidades que nos interessam\n                chunk_filtrado_regional = chunk[chunk['PA_UFMUN'].isin(lista_codigos_int)]\n                \n                if not chunk_filtrado_regional.empty:\n                    lista_chunks_regional.append(chunk_filtrado_regional)\n\n    print(\"Leitura em chunks conclu√≠da!\")\n    \n    # --- Etapa 3: Juntar os \"Peda√ßos\" das 3 cidades ---\n    df_regional = pd.concat(lista_chunks_regional, ignore_index=True)\n    \n    print(f\"Tabela regional criada com {len(df_regional)} registros.\")\n    \n    # --- Etapa 4: An√°lise Comparativa ---\n    \n    # Mapear os c√≥digos de volta para os nomes das cidades\n    # (Criamos um dicion√°rio invertido)\n    mapa_nomes_cidades = {v: k for k, v in codigos_cidades.items()}\n    df_regional['NOME_CIDADE'] = df_regional['PA_UFMUN'].map(mapa_nomes_cidades)\n    \n    # Agrupar por cidade e calcular as m√©tricas\n    df_comparativo = df_regional.groupby('NOME_CIDADE').agg(\n        TOTAL_PROCEDIMENTOS=('PA_UFMUN', 'size'),\n        TOTAL_VALOR_APROVADO=('PA_VALAPR', 'sum')\n    ).reset_index()\n\n    print(\"\\n--- üìä Resultado Comparativo (Volume e Valor) ---\")\n    print(df_comparativo)\n    \n    # --- Etapa 5: Gerar Gr√°fico Comparativo (Volume) com Seaborn ---\n    print(\"\\nGerando gr√°fico comparativo (Volume)...\")\n    \n    plt.figure(figsize=(10, 6))\n    ax_vol = sns.barplot(\n        data=df_comparativo.sort_values('TOTAL_PROCEDIMENTOS', ascending=False),\n        x='NOME_CIDADE',\n        y='TOTAL_PROCEDIMENTOS'\n    )\n    plt.title('Comparativo Regional: Volume de Procedimentos', fontsize=16)\n    plt.xlabel('Cidade', fontsize=12)\n    plt.ylabel('Total de Procedimentos', fontsize=12)\n    plt.tight_layout()\n    plt.savefig('comparativo_regional_volume.png')\n    print(\"Gr√°fico 'comparativo_regional_volume.png' salvo.\")\n    \n    # --- Etapa 6: Gerar Gr√°fico Comparativo (Financeiro) com Seaborn ---\n    print(\"\\nGerando gr√°fico comparativo (Financeiro)...\")\n\n    # Fun√ß√£o para formatar o eixo Y em Reais (R$ Milh√µes)\n    def format_reais(x, pos):\n        return f'R$ {x/1e6:.1f} M'\n\n    plt.figure(figsize=(10, 6))\n    ax_fin = sns.barplot(\n        data=df_comparativo.sort_values('TOTAL_VALOR_APROVADO', ascending=False),\n        x='NOME_CIDADE',\n        y='TOTAL_VALOR_APROVADO'\n    )\n    ax_fin.yaxis.set_major_formatter(FuncFormatter(format_reais))\n    plt.title('Comparativo Regional: Valor Financeiro Aprovado', fontsize=16)\n    plt.xlabel('Cidade', fontsize=12)\n    plt.ylabel('Valor Total Aprovado (R$)', fontsize=12)\n    plt.tight_layout()\n    plt.savefig('comparativo_regional_financeiro.png')\n    print(\"Gr√°fico 'comparativo_regional_financeiro.png' salvo.\")\n    \nexcept NameError as e:\n    print(f\"Erro: {e}\")\n    print(\"\\n--- ‚ö†Ô∏è Aten√ß√£o! ---\")\n    print(\"Parece que o estado da mem√≥ria do notebook foi perdido (kernel reiniciou).\")\n    print(\"Por favor, rode novamente a c√©lula que carrega TODOS os 10 arquivos CSV originais (no in√≠cio do notebook) e tente este c√≥digo novamente.\")\nexcept Exception as e:\n    print(f\"Ocorreu um erro inesperado: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T01:04:35.190447Z","iopub.execute_input":"2025-11-13T01:04:35.190712Z","iopub.status.idle":"2025-11-13T01:06:57.166741Z","shell.execute_reply.started":"2025-11-13T01:04:35.190683Z","shell.execute_reply":"2025-11-13T01:06:57.165688Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Na etapa final da an√°lise, comparamos Iju√≠ com os outros dois grandes polos regionais: *Santa Rosa e Cruz Alta*. Para fazer isso sem sobrecarregar a mem√≥ria, utilizamos a metodologia de chunksize (leitura em peda√ßos), filtrando os *13,2 milh√µes* de registros totais para extrair apenas os procedimentos realizados nos estabelecimentos desses tr√™s munic√≠pios. Em seguida, agrupamos os dados para comparar o Volume Total de Procedimentos e o *Valor Total Aprovado (R$)*.\n\nDescobertas e Resultados\n\n- **Volume (Gr√°fico comparativo_regional_volume.png):**\n\n1. **Iju√≠:** 160.060 procedimentos\n\n2. **Cruz Alta:** 93.540 procedimentos\n\n3. *Santa Rosa:* 56.116 procedimentos\n\n- **Financeiro (Gr√°fico comparativo_regional_financeiro.png):**\n\n1. **Iju√≠:** R$ 13,32 milh√µes\n\n2. **Santa Rosa:** R$ 4,31 milh√µes\n\n3. **Cruz Alta:** R$ 2,96 milh√µes","metadata":{}},{"cell_type":"markdown","source":"# Conclus√£o: Informa√ß√µes Estrat√©gicas para a Gest√£o\nEste trabalho transformou **13,2 milh√µes** de registros de dados brutos do **SIASUS** em informa√ß√µes estrat√©gicas acion√°veis para a gest√£o da sa√∫de em Iju√≠.\n\nA an√°lise completa da produ√ß√£o ambulatorial do munic√≠pio (**160.060 procedimentos analisados**) revelou quatro pilares principais que definem o sistema de sa√∫de local:\n\n1. **Iju√≠ √© um Polo Macrorregional**\n\nA rede de sa√∫de de Iju√≠ n√£o serve apenas aos seus cidad√£os. A an√°lise de fluxo (Item 4) revelou que a demanda √© quase perfeitamente dividida: *52%* dos pacientes s√£o de Iju√≠ **(78.559)* e 48%* v√™m de outros munic√≠pios *(71.062)*, com destaque para *Panambi e Joia*.\n\n**Estrat√©gia:** O planejamento de capacidade e a pactua√ß√£o financeira com munic√≠pios vizinhos s√£o fundamentais para a sustentabilidade do sistema.\n\n2. **O Or√ßamento √© Definido pelo Alto Custo (N√£o pelo Volume)**\n\n**A an√°lise de Volume vs. Valor (Item 5)** mostrou que os servi√ßos que geram fila (consultas, sa√∫de mental) n√£o s√£o os que geram custo.\n\n**O Custo** √© ditado pela alta complexidade, especificamente Oncologia (**R$ 3,82 milh√µes**) e **Nefrologia/Hemodi√°lise (R$ 1,16 milh√£o)**.\n\n**O Volume √© ditado pela Aten√ß√£o Especializada (37 mil consultas) e Sa√∫de Mental (20 mil atendimentos).**\n\n**Estrat√©gia:** A gest√£o exige duas frentes: uma de efici√™ncia de fluxo (para as consultas/CAPS) e uma de gest√£o de contratos e custos (para Oncologia/Nefrologia).\n\n3. **O Sistema √© Focado no Envelhecimento**\n\nA **\"tend√™ncia de envelhecimento\"** n√£o √© um problema futuro; √© a realidade atual (Item 6). A idade mediana dos pacientes √© de 58 anos.\n\n**83%** de todos os procedimentos de **Cardiologia e Oncologia** s√£o realizados em pacientes com 50 anos ou mais.\n\n**Estrat√©gia:** O planejamento de especialidades e a aloca√ß√£o de recursos do munic√≠pio devem ser primariamente focados no cuidado ao paciente idoso e no tratamento de doen√ßas cr√¥nicas.\n\n4. **Alerta Cr√≠tico: O Ponto Cego do \"CID N√£o Informado\"**\n\nA maior amea√ßa √† gest√£o estrat√©gica √© a qualidade dos dados (Item 3). **60%** de todos os procedimentos (**89.693 registros**) n√£o possuem um diagn√≥stico (CID) informado.\n\n**Estrat√©gia:** √â imposs√≠vel realizar um planejamento epidemiol√≥gico eficaz sem saber quais doen√ßas est√£o sendo tratadas. √â urgente auditar o sistema de registro (principalmente no **HCI e Bom Pastor**) para corrigir essa falha, que atualmente cria o maior ponto cego para a gest√£o.","metadata":{}}]}